{"cells":[{"cell_type":"markdown","metadata":{"id":"iLSvrFtkoJCq"},"source":["# PREDICTING SEPSIS RISK DURING IN-PATIENT ADMISSIONS\n","*Client: Royal Perth Hospital*\n","\n","*Team: Group 7*"]},{"cell_type":"markdown","metadata":{"id":"Bh5XhpzXoJCs"},"source":["# Readme\n","The following libraries need to be installed in order to run the source code."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dez_74VxoJCs"},"outputs":[],"source":["import pandas as pd\n","import numpy as np, warnings\n","from pathlib import Path\n","import os\n","import sweetviz as sv\n","from importlib import reload\n","\n","os.chdir('D:/Kha/UWA/CITS5553/sepsis_prediction/data-science-capstone-project/Kha Huynh')\n","import my_util\n","reload(my_util)\n","\n","np.warnings = warnings\n","os.chdir('D:/Kha/UWA/CITS5553/sepsis_prediction/data-science-capstone-project')"]},{"cell_type":"markdown","metadata":{"id":"j5Qkb70boJCt"},"source":["# 1.Dataset Processing"]},{"cell_type":"markdown","metadata":{"id":"fzimIvgloJCt"},"source":["## 1.1 Data Cleaning"]},{"cell_type":"markdown","metadata":{"id":"wmIbPuN1oJCt"},"source":["Load the dataset. The following tables are loaded for this project:\n","- PATIENTS\n","- ADMISSIONS\n","- DIAGNOSES_ICD\n","- LABEVENTS\n","- MICROBIOLOGYEVENTS\n","- D_ICD_DIAGNOSES\n","- D_ITEMS"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MsFFxbWfoJCt"},"outputs":[],"source":["# load transaction dataset\n","df_patients = pd.read_csv('data\\PATIENTS.csv')\n","df_admissions = pd.read_csv('data\\ADMISSIONS.csv')\n","df_diagnoses_icd = pd.read_csv('data\\DIAGNOSES_ICD.csv')\n","df_labevents = pd.read_csv('data\\LABEVENTS.csv')\n","df_microbiologyevents = pd.read_csv('data\\MICROBIOLOGYEVENTS.csv')\n","\n","# load description tables\n","df_desc_icd = pd.read_csv('data\\D_ICD_DIAGNOSES.csv')\n","df_desc_labitems = pd.read_csv('data\\D_LABITEMS.csv')\n","df_desc_items = pd.read_csv('data\\D_ITEMS.csv')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["df_labevents = pd.read_csv('data\\LABEVENTS.csv')\n","df_desc_labitems = pd.read_csv('data\\D_LABITEMS.csv')\n","df_labevents_processed = df_labevents.drop_duplicates(subset=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME'], ignore_index=True)[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME']]\n","df_labevents_processed = df_labevents.drop_duplicates(subset=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME'], ignore_index=True)[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME']]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Convert the following datetime columns to datetime format\n","# patients: DOB to date format, we not care about the birth time\n","df_patients['DOB'] = pd.to_datetime(df_patients['DOB'], format='%Y-%m-%d %H:%M:%S')\n","# admissions: ADMITTIME, DISCHTIME, EDREGTIME, EDOUTTIME\n","df_admissions['ADMITTIME'] = pd.to_datetime(df_admissions['ADMITTIME'], format='%Y-%m-%d %H:%M:%S')\n","df_admissions['DISCHTIME'] = pd.to_datetime(df_admissions['DISCHTIME'], format='%Y-%m-%d %H:%M:%S')\n","df_admissions['EDREGTIME'] = pd.to_datetime(df_admissions['EDREGTIME'], format='%Y-%m-%d %H:%M:%S')\n","df_admissions['EDOUTTIME'] = pd.to_datetime(df_admissions['EDOUTTIME'], format='%Y-%m-%d %H:%M:%S')\n","# labevents: CHARTTIME\n","df_labevents['CHARTTIME'] = pd.to_datetime(df_labevents['CHARTTIME'], format='%Y-%m-%d %H:%M:%S')\n","# microbiologyevents: CHARTDATE to date format and CHARTTIME to datetime format\n","df_microbiologyevents['CHARTDATE'] = pd.to_datetime(df_microbiologyevents['CHARTDATE'], format='%Y-%m-%d')\n","df_microbiologyevents['CHARTTIME'] = pd.to_datetime(df_microbiologyevents['CHARTTIME'], format='%Y-%m-%d %H:%M:%S')"]},{"cell_type":"markdown","metadata":{},"source":["The DIAGNOSES_ICD tables has a column ICD9_CODE which is the code for each disease diagnosed for the patient.\n","\n","The Sepsis has 6 codes: ['77181', '99591', '99592', '67020', '67022', '67024']\n","\n","We'll introduce a new column, IS_SEPSIS, as a binary classifier (1 for 6 sepsis ICD9 codes, 0 otherwise) for the target variable."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# retrieve all sepsis icd code\n","sepsis_icd =  df_desc_icd[df_desc_icd.apply(lambda x:'seps' in x['SHORT_TITLE'].lower(),axis=1)]['ICD9_CODE'].values\n","# add new binary classifier target variable\n","df_diagnoses_icd['IS_SEPSIS'] = df_diagnoses_icd.apply(lambda x: 1 if x['ICD9_CODE'] in sepsis_icd else 0, axis=1)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["try:\n","    df_demographic = pd.read_csv('data\\demographic.csv')\n","except:\n","    # merge the patients and admission tables to a demographic dataframe\n","    df_demographic = pd.merge(df_admissions, df_patients[['SUBJECT_ID', 'GENDER', 'DOB', 'EXPIRE_FLAG']], on='SUBJECT_ID')\n","    # create an age column to each case\n","    df_demographic['AGE'] = ((df_demographic['ADMITTIME'].dt.date - df_demographic['DOB'].dt.date) // 365).dt.days\n","    # add column IS_SEPSIS to demographic data indicating which case is diagnosed with sepsis\n","    df_demographic['IS_SEPSIS'] = df_demographic.apply(lambda x: my_util.check_sepsis(x['SUBJECT_ID'], x['HADM_ID'], df_diagnoses_icd), axis=1)\n","    my_util.save_csv(df_demographic, 'data\\demographic.csv')"]},{"cell_type":"markdown","metadata":{},"source":["there are 5406 admissions has IS_SEPSIS=1.\n","\n","But in the df_diagnoses_icd has 5409. The code below found that 3 HADM_ID is diagnosed sespsis 2 twice (with the same/different sepsis icd9_code)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# there are 3 HADM_ID are predicted sepsis twice in diagnoses table\n","df_diagnoses_icd[df_diagnoses_icd['IS_SEPSIS'] == 1]['HADM_ID'][df_diagnoses_icd[df_diagnoses_icd['IS_SEPSIS'] == 1]['HADM_ID'].duplicated()]"]},{"cell_type":"markdown","metadata":{},"source":["Plotting the boxplot of age between admissions sepsis and non-sepsis below found that older people is likely to have sepsis than the young."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_demographic.boxplot(column=['AGE'], by='IS_SEPSIS')"]},{"cell_type":"markdown","metadata":{},"source":["Looking at the boxplot we see some outliers in the age feature, some patients around 300 years old."]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of patients aged over 100 years old is: 1991 patients (4.28% over all patients)\n","- 345 of them has sepsis (7.22% over all sepsis patients)\n","The number of admissions aged over 100 years old is: 2616 admissions (4.44% over all admissions)\n","- 389 of them has sepsis (7.20% over all sepsis patients)\n"]}],"source":["a = len(df_demographic[df_demographic.AGE>100]['SUBJECT_ID'].unique())\n","b = len(df_demographic[df_demographic.AGE>100]['SUBJECT_ID'].unique())/len(df_demographic['SUBJECT_ID'].unique())*100\n","print('The number of patients aged over 100 years old is: {} patients ({:.2f}% over all patients)'.format(a,b))\n","\n","a = len(df_demographic[(df_demographic.AGE>100) & (df_demographic.IS_SEPSIS==1)]['SUBJECT_ID'].unique())\n","b = len(df_demographic[(df_demographic.AGE>100) & (df_demographic.IS_SEPSIS==1)]['SUBJECT_ID'].unique())/len(df_demographic[df_demographic.IS_SEPSIS==1]['SUBJECT_ID'].unique())*100\n","print('- {} of them has sepsis ({:.2f}% over all sepsis patients)'.format(a,b))\n","\n","a = len(df_demographic[df_demographic.AGE>100])\n","b = len(df_demographic[df_demographic.AGE>100])/len(df_demographic)*100\n","print('The number of admissions aged over 100 years old is: {} admissions ({:.2f}% over all admissions)'.format(a,b))\n","\n","a = len(df_demographic[(df_demographic.AGE>100) & (df_demographic.IS_SEPSIS==1)])\n","b = len(df_demographic[(df_demographic.AGE>100) & (df_demographic.IS_SEPSIS==1)])/len(df_demographic[df_demographic.IS_SEPSIS==1])*100\n","print('- {} of them has sepsis ({:.2f}% over all sepsis patients)'.format(a,b))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# no need to run this\n","df_labevents_processed = df_labevents.drop_duplicates(subset=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME'], ignore_index=True)[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME']]\n","my_util.save_csv(df_labevents_processed, 'data\\output_csv\\df_labevents_processed.csv')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["df_labevents_processed = pd.read_csv(\"data\\output_csv\\df_labevents_processed.csv\")\n","df_labevents_processed['CHARTTIME'] = pd.to_datetime(df_labevents_processed['CHARTTIME'], format='%Y-%m-%d %H:%M:%S')\n","df_labevents_processed['HADM_ID'] = df_labevents_processed['HADM_ID'].astype('Int64')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# no need to run this code\n","df_labevents_processed = my_util.create_labevent_columns(df_labevents_processed, df_desc_labitems[:300]['ITEMID'])\n","my_util.save_csv(df_labevents_processed, 'data\\output_csv\\df_labevents_processed_51346_50972.csv')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# no need to run this code\n","df_labevents_processed = my_util.create_labevent_columns(df_labevents_processed, df_desc_labitems[300:]['ITEMID'])\n","my_util.save_csv(df_labevents_processed, 'data\\output_csv\\df_labevents_processed_50973_51555.csv')"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'ITEM_ID'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32md:\\Kha\\UWA\\CITS5553\\sepsis_prediction\\data-science-capstone-project\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n","File \u001b[1;32md:\\Kha\\UWA\\CITS5553\\sepsis_prediction\\data-science-capstone-project\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32md:\\Kha\\UWA\\CITS5553\\sepsis_prediction\\data-science-capstone-project\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'ITEM_ID'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[120], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m             new_row \u001b[39m=\u001b[39m [subject_id, hadm_id, charttime, value]\n\u001b[0;32m     16\u001b[0m             df_labevents_processed\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(df_labevents_processed)] \u001b[39m=\u001b[39m new_row\n\u001b[1;32m---> 18\u001b[0m add_column(df_labevents_processed, df_labevents[:\u001b[39m20\u001b[39;49m])\n","Cell \u001b[1;32mIn[120], line 6\u001b[0m, in \u001b[0;36madd_column\u001b[1;34m(df_labevents_processed, data)\u001b[0m\n\u001b[0;32m      4\u001b[0m hadm_id \u001b[39m=\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mHADM_ID\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m charttime \u001b[39m=\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mCHARTTIME\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m item_id \u001b[39m=\u001b[39m x[\u001b[39m'\u001b[39;49m\u001b[39mITEM_ID\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      7\u001b[0m flag \u001b[39m=\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mFLAG\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m value \u001b[39m=\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mVALUE\u001b[39m\u001b[39m'\u001b[39m]\n","File \u001b[1;32md:\\Kha\\UWA\\CITS5553\\sepsis_prediction\\data-science-capstone-project\\.venv\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n","File \u001b[1;32md:\\Kha\\UWA\\CITS5553\\sepsis_prediction\\data-science-capstone-project\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n","File \u001b[1;32md:\\Kha\\UWA\\CITS5553\\sepsis_prediction\\data-science-capstone-project\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'ITEM_ID'"]}],"source":["def add_column(df_labevents_processed, data):\n","    for i, x in data.iterrows():\n","        subject_id = x['SUBJECT_ID']\n","        hadm_id = x['HADM_ID']\n","        charttime = x['CHARTTIME']\n","        item_id = x['ITEM_ID']\n","        flag = x['FLAG']\n","        value = x['VALUE']\n","        r_index = df_labevents_processed[(df_labevents_processed.SUBJECT_ID == subject_id) & (df_labevents_processed.HADM_ID==hadm_id) &\n","         (df_labevents_processed.CHARTTIME==charttime)].index\n","        df_labevents_processed.at[r_index, item_id] = value\n","        df_labevents_processed.at[r_index, f\"{item_id}_FLAG\"] = flag\n","\n","add_column(df_labevents_processed, df_labevents[:20])"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>HADM_ID</th>\n","      <th>CHARTTIME</th>\n","      <th>VALUE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 16:07:00</td>\n","      <td>7.39</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>ART</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>0.93</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>NOT INTUBATED</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>1.8</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>7.42</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>80</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-12 18:17:00</td>\n","      <td>35.8</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>8.4</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>109</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>1.7</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>1.8</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>3.7</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>2101-10-13 03:00:00</td>\n","      <td>4.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    SUBJECT_ID  HADM_ID           CHARTTIME          VALUE\n","0            3      NaN 2101-10-12 16:07:00           7.39\n","1            3      NaN 2101-10-12 18:17:00            ART\n","2            3      NaN 2101-10-12 18:17:00             -1\n","3            3      NaN 2101-10-12 18:17:00             22\n","4            3      NaN 2101-10-12 18:17:00           0.93\n","5            3      NaN 2101-10-12 18:17:00  NOT INTUBATED\n","6            3      NaN 2101-10-12 18:17:00            1.8\n","7            3      NaN 2101-10-12 18:17:00             33\n","8            3      NaN 2101-10-12 18:17:00           7.42\n","9            3      NaN 2101-10-12 18:17:00             80\n","10           3      NaN 2101-10-12 18:17:00           35.8\n","11           3      NaN 2101-10-13 03:00:00             13\n","12           3      NaN 2101-10-13 03:00:00             23\n","13           3      NaN 2101-10-13 03:00:00            8.4\n","14           3      NaN 2101-10-13 03:00:00            109\n","15           3      NaN 2101-10-13 03:00:00            1.7\n","16           3      NaN 2101-10-13 03:00:00            137\n","17           3      NaN 2101-10-13 03:00:00            1.8\n","18           3      NaN 2101-10-13 03:00:00            3.7\n","19           3      NaN 2101-10-13 03:00:00            4.3"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["df_labevents_processed"]},{"cell_type":"markdown","metadata":{},"source":["Next we inspect the tables to see any unexpected points"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["analysis = sv.analyze(df_patient)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["analysis.show_notebook()"]},{"cell_type":"markdown","metadata":{"id":"BynxBJyjoJCt"},"source":["## 1.2 Data Exploration"]},{"cell_type":"markdown","metadata":{"id":"sa0vmSCyoJCt"},"source":["## 1.3 Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"SN271srIoJCu"},"source":["# 2.Sepsis Risk Predicting Model Implementation"]},{"cell_type":"markdown","metadata":{"id":"t6U0mrw1oJCu"},"source":["## 2.1 Logistics Regression Model"]},{"cell_type":"markdown","metadata":{"id":"j60ILnKZoJCu"},"source":["## 2.2 Random Forest Model"]},{"cell_type":"markdown","metadata":{"id":"9KRDjGP_oJCu"},"source":["## 2.3 Gradient Boosted Model"]},{"cell_type":"markdown","metadata":{"id":"fgaUcAAeoJCu"},"source":["## 2.4 LSTM Model"]},{"cell_type":"markdown","metadata":{"id":"n3DakgKuoJCu"},"source":["## 2.5 LSTM + Attention Model"]},{"cell_type":"markdown","metadata":{"id":"m9P86G5VoJCu"},"source":["## 2.6 Clustering Model"]},{"cell_type":"markdown","metadata":{"id":"pGsW9n1zoJCu"},"source":["# 3.Model Testing"]},{"cell_type":"markdown","metadata":{"id":"k56f3Pj_oJCu"},"source":["# 4.Local and Global Feature Explanation"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
