{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline\n",
    "*Client: Royal Perth Hospital*\n",
    "\n",
    "*Team: Group 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme\n",
    "The following libraries need to be installed in order to run the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from importlib import reload\n",
    "# import utility functions\n",
    "import src.utils as utils\n",
    "\n",
    "# Note: to run main notebook from root directory, use:\n",
    "ROOT_DIR = Path('')\n",
    "# setup OS agnostic pathnames\n",
    "# ROOT_DIR = Path('..')\n",
    "\n",
    "import src.DataLoader as DataLoader\n",
    "reload(DataLoader)\n",
    "\n",
    "dataLoader = DataLoader.DataLoader(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset. The following tables are loaded for this project:\n",
    "- LABEVENTS\n",
    "- MICROBIOLOGYEVENTS\n",
    "- D_ICD_DIAGNOSES\n",
    "- D_ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_icd, df_desc_labitems, df_desc_items = dataLoader.load_descriptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DIAGNOSES_ICD tables has a column ICD9_CODE which is the code for each disease diagnosed for the patient.\n",
    "\n",
    "- The Sepsis has 6 codes: ['77181', '99591', '99592', '67020', '67022', '67024']\n",
    "\n",
    "- We'll introduce a new column, IS_SEPSIS, as a binary classifier (1 for 6 sepsis ICD9 codes, 0 otherwise) for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses_icd = dataLoader.load_diagnoses_icd(df_desc_icd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Demographic dataframe is a combination of the patient and admission datasets. Adding some columns:\n",
    "- AGE: the age of the patient at the admitted year\n",
    "- IS_SEPSIS: indicating whether this is a sepsis case or not\n",
    "\n",
    "\n",
    "The labevents dataframe is loaded. Admissions under 18 years old are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 8210 admissions with AGE < 18\n"
     ]
    }
   ],
   "source": [
    "df_demographic = dataLoader.load_demographic(df_diagnoses_icd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace those with aged > 100 by the median age of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographic = dataLoader.demographic_clean_AGE(df_demographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labevents dataframe is loaded. The records of admissions under 18 years old are removed.\n",
    "- The empty HADM_ID is this are cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = dataLoader.load_labevents(df_demographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the TIME from for labevents from ADMITTIME to CHARTTIME\n",
    "- A column NEW_ADMITTIME is added: if CHARTTIME < ADMITTIME, the NEW_ADMITTIME is the CHARTTIME, otherwise, use the ADMITTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labevents = dataLoader.labevents_compute_TIME(df_labevents, df_demographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader.create_train_data(df_labevents, df_demographic, df_desc_labitems, hours=0, feature_no=20, output_filename=ROOT_DIR/\"data/Model input data/test_new_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader.create_train_data(df_labevents, df_demographic, df_desc_labitems, hours=2, feature_no=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader.create_train_data(df_labevents, df_demographic, df_desc_labitems, hours=4, feature_no=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = dataLoader.create_train_data_sequence(df_labevents, df_demographic, df_desc_labitems, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = dataLoader.create_train_data_sequence(df_labevents, df_demographic, df_desc_labitems, 8, output_filename = ROOT_DIR / 'data/Model input data/t8_sequence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = dataLoader.extract_train_data_by_features(df_labevents, df_demographic, df_desc_labitems, 4, ROOT_DIR / 'data/potential_labevents_count_with_proportion.csv', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ITEMID_51222': 'Hemoglobin (51222)',\n",
       " 'ITEMID_51221': 'Hematocrit (51221)',\n",
       " 'ITEMID_51279': 'Red Blood Cells (51279)',\n",
       " 'ITEMID_50931': 'Glucose (50931)',\n",
       " 'ITEMID_51301': 'White Blood Cells (51301)',\n",
       " 'ITEMID_51256': 'Neutrophils (51256)',\n",
       " 'ITEMID_51274': 'PT (51274)',\n",
       " 'ITEMID_50970': 'Phosphate (50970)',\n",
       " 'ITEMID_51006': 'Urea Nitrogen (51006)',\n",
       " 'ITEMID_50893': 'Calcium, Total (50893)',\n",
       " 'ITEMID_51244': 'Lymphocytes (51244)',\n",
       " 'ITEMID_50902': 'Chloride (50902)',\n",
       " 'ITEMID_50882': 'Bicarbonate (50882)',\n",
       " 'ITEMID_50821': 'pO2 (50821)',\n",
       " 'ITEMID_51265': 'Platelet Count (51265)',\n",
       " 'ITEMID_51248': 'MCH (51248)',\n",
       " 'ITEMID_51275': 'PTT (51275)',\n",
       " 'ITEMID_51277': 'RDW (51277)',\n",
       " 'ITEMID_50820': 'pH (50820)',\n",
       " 'ITEMID_50818': 'pCO2 (50818)',\n",
       " 'ITEMID_50885': 'Bilirubin, Total (50885)',\n",
       " 'ITEMID_50912': 'Creatinine (50912)'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemID = [\"ITEMID_51222\", \"ITEMID_51221\", \"ITEMID_51279\", \"ITEMID_50931\", \"ITEMID_51301\", \"ITEMID_51256\", \"ITEMID_51274\", \n",
    "          \"ITEMID_50970\", \"ITEMID_51006\", \"ITEMID_50893\", \"ITEMID_51244\", \"ITEMID_50902\", \"ITEMID_50882\", \"ITEMID_50821\", \n",
    "          \"ITEMID_51265\", \"ITEMID_51248\", \"ITEMID_51275\", \"ITEMID_51277\", \"ITEMID_50820\", \"ITEMID_50818\", \"ITEMID_50885\", \"ITEMID_50912\"]\n",
    "dataLoader.convert_itemid_to_title(itemID, df_desc_labitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "sepsis_data = df_demographic\n",
    "\n",
    "microbiology_data = dataLoader.load_microbiologyevents()\n",
    "microbiology_data\n",
    "# Filter the microbiology data to include only rows with sepsis patients\n",
    "sepsis_hadm_ids = sepsis_data['HADM_ID'].tolist()\n",
    "valid_spec_types = ['URINE', 'BLOOD CULTURE', 'STOOL']\n",
    "\n",
    "filtered_microbiology_data = microbiology_data[microbiology_data['HADM_ID'].isin(sepsis_hadm_ids)]\n",
    "\n",
    "filtered_microbiology_data = filtered_microbiology_data[filtered_microbiology_data['SPEC_TYPE_DESC'].isin(valid_spec_types)]\n",
    "# Group the filtered microbiology data by bacteria and count occurrences\n",
    "bacteria_counts = filtered_microbiology_data['ORG_NAME'].value_counts()\n",
    "\n",
    "# Sort the bacteria by frequency in descending order\n",
    "bacteria_counts = bacteria_counts.sort_values(ascending=False)\n",
    "top_30_bacteria_counts = bacteria_counts.head(30)\n",
    "# Create a bar chart to show the most common bacteria affecting sepsis patients\n",
    "plt.figure(figsize=(8, 10))  # Adjust the figure size as needed\n",
    "top_30_bacteria_counts = top_30_bacteria_counts.iloc[::-1]\n",
    "plt.barh(top_30_bacteria_counts.index, top_30_bacteria_counts.values, color='skyblue')\n",
    "plt.title('Top 30 Most Common Bacteria Affecting Sepsis Patients')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Bacteria')\n",
    "\n",
    "# Show the bar chart\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# In this updated code, we've changed the plt.bar to plt.barh to create a horizontal bar chart, which effectively rotates the plot 90 degrees to the right. We've also adjusted the figure size to ensure the plot looks appropriate in the landscape orientation.\n",
    "\n",
    "# Show the bar chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#06/10/2023 start  CHECKING the importance of Microbiology events\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "# Sample data (replace with your actual data)\n",
    "sepsis_data = df_demographic\n",
    "df_micro = pd.DataFrame(dataLoader.load_microbiologyevents())\n",
    "\n",
    "# Convert CHARTTIME column to datetime\n",
    "df_micro['CHARTTIME'] = pd.to_datetime(df_micro['CHARTTIME'], errors='coerce', format='%d/%m/%Y %H:%M')\n",
    "\n",
    "\n",
    "# Merge the two dataframes based on HADM_ID\n",
    "df_micro_demo = pd.merge(df_micro, sepsis_data, on='HADM_ID')\n",
    "\n",
    "\n",
    "selected_columns = ['HADM_ID', 'CHARTTIME', 'IS_SEPSIS', 'ORG_NAME']\n",
    "filtered_df = df_micro_demo[selected_columns]\n",
    "filtered_df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "merged_df_sorted = filtered_df.sort_values(by='HADM_ID')\n",
    "\n",
    "\n",
    "# Define conditions for filtering the DataFrame\n",
    "condition1 = (merged_df_sorted['IS_SEPSIS'] == 1) & (~merged_df_sorted['ORG_NAME'].isnull())\n",
    "condition2 = (merged_df_sorted['IS_SEPSIS'] == 0) & (merged_df_sorted['ORG_NAME'].isnull())\n",
    "\n",
    "\n",
    "merged_df_sorted['Flag'] = np.where(condition1 | condition2, 'Pass', 'Fail')\n",
    "\n",
    "\n",
    "merged_df_sorted.to_excel('filtered_and_flagged_data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into 'Pass' and 'Fail' DataFrames\n",
    "pass_df = merged_df_sorted[merged_df_sorted['Flag'] == 'Pass']\n",
    "fail_df = merged_df_sorted[merged_df_sorted['Flag'] == 'Fail']\n",
    "\n",
    "# Get unique rows for each HADM_ID in 'Pass' DataFrame\n",
    "unique_pass_df = pass_df.drop_duplicates(subset='HADM_ID')\n",
    "\n",
    "# Get unique rows for each HADM_ID in 'Fail' DataFrame\n",
    "unique_fail_df = fail_df.drop_duplicates(subset='HADM_ID')\n",
    "\n",
    "# Export 'Pass' and 'Fail' DataFrames to Excel files\n",
    "pass_df.to_excel('pass_data.xlsx', index=False)\n",
    "fail_df.to_excel('fail_data.xlsx', index=False)\n",
    "\n",
    "# Export unique rows for 'Pass' and 'Fail' HADM_ID to Excel files\n",
    "unique_pass_df.to_excel('unique_pass_data.xlsx', index=False)\n",
    "unique_fail_df.to_excel('unique_fail_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate unique_pass_df and unique_fail_df without overlapping HADM_ID\n",
    "\n",
    "filtered_fail_df = unique_fail_df[~unique_fail_df['HADM_ID'].isin(unique_pass_df['HADM_ID'])]\n",
    "\n",
    "# Concatenate pass_df and filtered_fail_df into whole_df\n",
    "whole_df = pd.concat([unique_pass_df, filtered_fail_df], ignore_index=True)\n",
    "\n",
    "# Export the concatenated DataFrame to an Excel file\n",
    "whole_df.to_excel('whole_data_pass_and_fail.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of 'Pass' and 'Fail' in the 'Flag' column\n",
    "flag_counts = whole_df['Flag'].value_counts()\n",
    "\n",
    "# Calculate proportions\n",
    "pass_proportion = flag_counts.get('Pass', 0) / len(whole_df)\n",
    "fail_proportion = flag_counts.get('Fail', 0) / len(whole_df)\n",
    "\n",
    "# Print proportions\n",
    "print(f'Proportion of Flag = Pass: {pass_proportion:.2f}')\n",
    "print(f'Proportion of Flag = Fail: {fail_proportion:.2f}')\n",
    "\n",
    "labels = ['Pass', 'Fail']\n",
    "sizes = [pass_proportion, fail_proportion]  # Replace with your actual proportions\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "explode = (0.1, 0)  # Explode the \"Pass\" slice (optional)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "\n",
    "plt.title('Proportion of Pass and Fail of Theory')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#06/10/2023 end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
